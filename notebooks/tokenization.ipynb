{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize Amharic text using various approaches, including traditional rule-based, statistical, and pre-trained models. We will:\n",
    "\n",
    "* Tokenize using amseg.amharicSegmenter.\n",
    "* Tokenize using nltk.tokenizer.\n",
    "* Tokenize using spm.SentencePieceProcessor.\n",
    "* Tokenize using XLM-Roberta-Base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liulj\\Desktop\\KAIM\\KAIM-Week-5\\Amharic-NER\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\liulj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import basic libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from amseg.amharicSegmenter import AmharicSegmenter\n",
    "from transformers import AutoTokenizer\n",
    "nltk.download('punkt')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get working directory\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "# Import basic functions from the scripts folder\n",
    "from scripts.tokenization import amseg_tokenizer, nltk_tokenizer, regex_tokenizer, xlm_roberta_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/preprocessed_telegram_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>Message Id</th>\n",
       "      <th>Message Text</th>\n",
       "      <th>Message Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>አዳማ ገበያ - Adama gebeya</td>\n",
       "      <td>@gebeyaadama</td>\n",
       "      <td>4310</td>\n",
       "      <td>nipple shield የእናት ጡት ጫፍ ማራዘሚያ ዋጋ 450 ብር 09117...</td>\n",
       "      <td>2025-01-17 10:32:58+00:00</td>\n",
       "      <td>../data/photos\\@gebeyaadama_4310.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>አዳማ ገበያ - Adama gebeya</td>\n",
       "      <td>@gebeyaadama</td>\n",
       "      <td>4309</td>\n",
       "      <td>Marc Jacob 3 in 1 glasses</td>\n",
       "      <td>2025-01-16 08:37:21+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>አዳማ ገበያ - Adama gebeya</td>\n",
       "      <td>@gebeyaadama</td>\n",
       "      <td>4306</td>\n",
       "      <td>Marc Jacob 3 in 1 sunglass 3 መነፀር በ 1 የያዘ 1 ከስ...</td>\n",
       "      <td>2025-01-16 08:21:16+00:00</td>\n",
       "      <td>../data/photos\\@gebeyaadama_4306.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>አዳማ ገበያ - Adama gebeya</td>\n",
       "      <td>@gebeyaadama</td>\n",
       "      <td>4304</td>\n",
       "      <td>Door Bottom Sealer</td>\n",
       "      <td>2025-01-13 09:16:50+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>አዳማ ገበያ - Adama gebeya</td>\n",
       "      <td>@gebeyaadama</td>\n",
       "      <td>4303</td>\n",
       "      <td>Door Bottom Sealer አየር ከውጭ ወደ ቤት ውስጥ እንዳይገባ ይከ...</td>\n",
       "      <td>2025-01-13 09:16:45+00:00</td>\n",
       "      <td>../data/photos\\@gebeyaadama_4303.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Channel Title Channel Username  Message Id  \\\n",
       "0  አዳማ ገበያ - Adama gebeya     @gebeyaadama        4310   \n",
       "1  አዳማ ገበያ - Adama gebeya     @gebeyaadama        4309   \n",
       "2  አዳማ ገበያ - Adama gebeya     @gebeyaadama        4306   \n",
       "3  አዳማ ገበያ - Adama gebeya     @gebeyaadama        4304   \n",
       "4  አዳማ ገበያ - Adama gebeya     @gebeyaadama        4303   \n",
       "\n",
       "                                        Message Text  \\\n",
       "0  nipple shield የእናት ጡት ጫፍ ማራዘሚያ ዋጋ 450 ብር 09117...   \n",
       "1                          Marc Jacob 3 in 1 glasses   \n",
       "2  Marc Jacob 3 in 1 sunglass 3 መነፀር በ 1 የያዘ 1 ከስ...   \n",
       "3                                 Door Bottom Sealer   \n",
       "4  Door Bottom Sealer አየር ከውጭ ወደ ቤት ውስጥ እንዳይገባ ይከ...   \n",
       "\n",
       "                Message Date                            Media Path  \n",
       "0  2025-01-17 10:32:58+00:00  ../data/photos\\@gebeyaadama_4310.jpg  \n",
       "1  2025-01-16 08:37:21+00:00                                   NaN  \n",
       "2  2025-01-16 08:21:16+00:00  ../data/photos\\@gebeyaadama_4306.jpg  \n",
       "3  2025-01-13 09:16:50+00:00                                   NaN  \n",
       "4  2025-01-13 09:16:45+00:00  ../data/photos\\@gebeyaadama_4303.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to be tokenized\n",
    "tokenized_column = data['Message Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    nipple shield የእናት ጡት ጫፍ ማራዘሚያ ዋጋ 450 ብር 09117...\n",
       "1                            Marc Jacob 3 in 1 glasses\n",
       "2    Marc Jacob 3 in 1 sunglass 3 መነፀር በ 1 የያዘ 1 ከስ...\n",
       "3                                   Door Bottom Sealer\n",
       "4    Door Bottom Sealer አየር ከውጭ ወደ ቤት ውስጥ እንዳይገባ ይከ...\n",
       "Name: Message Text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_column.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amharic Segmentor Tokenization: using `amseg.amharicSegmenter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using the Amharic Segmenter\n",
    "amseg_tokens = tokenized_column.apply(amseg_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nipple',\n",
       "  'shield',\n",
       "  'የእናት',\n",
       "  'ጡት',\n",
       "  'ጫፍ',\n",
       "  'ማራዘሚያ',\n",
       "  'ዋጋ',\n",
       "  '450',\n",
       "  'ብር',\n",
       "  '0911762201',\n",
       "  '0972824252',\n",
       "  '0988404491',\n",
       "  '0922282582',\n",
       "  'በቴሌግራም',\n",
       "  'ለማዘዝ',\n",
       "  '@GebeyaAdama21',\n",
       "  'አድራሻችን',\n",
       "  'አዳማ',\n",
       "  'ፖስታ',\n",
       "  'ቤት',\n",
       "  'ሶሬቲ',\n",
       "  'ሞል',\n",
       "  'ምድር',\n",
       "  'ላይ',\n",
       "  'ሱ.ቁ',\n",
       "  '33',\n",
       "  'ይሄንን',\n",
       "  'በመጫን',\n",
       "  'የቤተሠባችን',\n",
       "  'አባል',\n",
       "  'ይሁኑ',\n",
       "  'የመረጡትን',\n",
       "  'እቃ',\n",
       "  'ይዘዙ',\n",
       "  '፤',\n",
       "  'ያሉበት',\n",
       "  'እናደርሳለን',\n",
       "  '!!',\n",
       "  'በኪስዎ',\n",
       "  'ጥሬ',\n",
       "  'ገንዘብ',\n",
       "  'ካልያዙ',\n",
       "  'በሞባይል',\n",
       "  'ማስተላለፍ',\n",
       "  'ይችላሉ',\n",
       "  '።']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amseg_tokens.head(1).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\liulj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using the NLTK tokenizer\n",
    "nltk_tokens = tokenized_column.apply(nltk_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [nipple, shield, የእናት, ጡት, ጫፍ, ማራዘሚያ, ዋጋ, 450,...\n",
       "1                     [Marc, Jacob, 3, in, 1, glasses]\n",
       "2    [Marc, Jacob, 3, in, 1, sunglass, 3, መነፀር, በ, ...\n",
       "3                               [Door, Bottom, Sealer]\n",
       "4    [Door, Bottom, Sealer, አየር, ከውጭ, ወደ, ቤት, ውስጥ, ...\n",
       "5    [6, in, 1, silicone, set, 6, እቃዎች, የያዘ, መመገቢያ,...\n",
       "6    [Foldable, High, Capacity, Travel, Bag, ውሃ, የማ...\n",
       "7    [ምግብ, ማስጀመሪያ, ሠኀን, የራሱ, ማንኪያ, ያለው, ልጆች, ጐትተው, ...\n",
       "8    [Grooming, set, 3in1, hair, clipper, Mini, sha...\n",
       "9    [Geemy, hair, clapper, መብራት, ጠፋ, አልጠፋ, ብሎ, መጨነ...\n",
       "Name: Message Text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_tokens.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using the regular expression tokenizer\n",
    "regex_tokens = tokenized_column.apply(regex_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [nipple, shield, የእናት, ጡት, ጫፍ, ማራዘሚያ, ዋጋ, 450,...\n",
       "1                     [Marc, Jacob, 3, in, 1, glasses]\n",
       "2    [Marc, Jacob, 3, in, 1, sunglass, 3, መነፀር, በ, ...\n",
       "3                               [Door, Bottom, Sealer]\n",
       "4    [Door, Bottom, Sealer, አየር, ከውጭ, ወደ, ቤት, ውስጥ, ...\n",
       "Name: Message Text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_tokens.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Trained XLM-Roberto-Base Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize using the XLM-RoBERTa tokenizer\n",
    "xlm_roberta_tokens = tokenized_column.apply(xlm_roberta_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁ni',\n",
       "  'pp',\n",
       "  'le',\n",
       "  '▁',\n",
       "  'shield',\n",
       "  '▁የእ',\n",
       "  'ናት',\n",
       "  '▁',\n",
       "  'ጡት',\n",
       "  '▁',\n",
       "  'ጫ',\n",
       "  'ፍ',\n",
       "  '▁ማ',\n",
       "  'ራ',\n",
       "  'ዘ',\n",
       "  'ሚያ',\n",
       "  '▁ዋጋ',\n",
       "  '▁450',\n",
       "  '▁ብር',\n",
       "  '▁09',\n",
       "  '11',\n",
       "  '762',\n",
       "  '201',\n",
       "  '▁09',\n",
       "  '72',\n",
       "  '82',\n",
       "  '42',\n",
       "  '52',\n",
       "  '▁09',\n",
       "  '884',\n",
       "  '04',\n",
       "  '491',\n",
       "  '▁09',\n",
       "  '22',\n",
       "  '28',\n",
       "  '25',\n",
       "  '82',\n",
       "  '▁በ',\n",
       "  'ቴ',\n",
       "  'ሌ',\n",
       "  'ግራ',\n",
       "  'ም',\n",
       "  '▁ለማ',\n",
       "  'ዘ',\n",
       "  'ዝ',\n",
       "  '▁@',\n",
       "  'Ge',\n",
       "  'be',\n",
       "  'ya',\n",
       "  'Adam',\n",
       "  'a',\n",
       "  '21',\n",
       "  '▁አድራሻ',\n",
       "  'ችን',\n",
       "  '▁አዳ',\n",
       "  'ማ',\n",
       "  '▁ፖ',\n",
       "  'ስታ',\n",
       "  '▁ቤት',\n",
       "  '▁',\n",
       "  'ሶ',\n",
       "  'ሬ',\n",
       "  'ቲ',\n",
       "  '▁ሞ',\n",
       "  'ል',\n",
       "  '▁ምድር',\n",
       "  '▁ላይ',\n",
       "  '▁',\n",
       "  'ሱ',\n",
       "  '.',\n",
       "  'ቁ',\n",
       "  '▁33',\n",
       "  '▁ይሄን',\n",
       "  'ን',\n",
       "  '▁በመ',\n",
       "  'ጫ',\n",
       "  'ን',\n",
       "  '▁የቤተ',\n",
       "  'ሠ',\n",
       "  'ባ',\n",
       "  'ችን',\n",
       "  '▁አባል',\n",
       "  '▁ይ',\n",
       "  'ሁኑ',\n",
       "  '▁የ',\n",
       "  'መረጡ',\n",
       "  'ትን',\n",
       "  '▁እ',\n",
       "  'ቃ',\n",
       "  '▁ይዘ',\n",
       "  'ዙ',\n",
       "  '፤',\n",
       "  '▁ያሉ',\n",
       "  'በት',\n",
       "  '▁እና',\n",
       "  'ደር',\n",
       "  'ሳ',\n",
       "  'ለን',\n",
       "  '!!',\n",
       "  '▁በ',\n",
       "  'ኪ',\n",
       "  'ስ',\n",
       "  'ዎ',\n",
       "  '▁ጥ',\n",
       "  'ሬ',\n",
       "  '▁ገንዘብ',\n",
       "  '▁ካል',\n",
       "  'ያዙ',\n",
       "  '▁በ',\n",
       "  'ሞባይል',\n",
       "  '▁ማስ',\n",
       "  'ተላለፍ',\n",
       "  '▁ይችላሉ',\n",
       "  '።']]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm_roberta_tokens.head(1).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** from the above Tokenization methode `Amharic Segment` is good for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save tokenized data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_file_path = '../data/tokenized_telegram_data.csv'\n",
    "amseg_tokens.to_csv(tokenized_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
